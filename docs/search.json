[
  {
    "objectID": "performance-culture-engagement.html#executive-summary",
    "href": "performance-culture-engagement.html#executive-summary",
    "title": "Building a Performance Culture I",
    "section": "Executive summary",
    "text": "Executive summary\nThis case study provides step-by-step instructions in R on how you can test the relationship between employee performance ratings and engagement survey results within your company, in order to understand whether top performers are also the most engaged employees."
  },
  {
    "objectID": "performance-culture-engagement.html#context-business-question",
    "href": "performance-culture-engagement.html#context-business-question",
    "title": "Building a Performance Culture I",
    "section": "Context & Business Question",
    "text": "Context & Business Question\nThe positive impact of employee engagement on employee performance has already been extensively documented in the literature, for example here, here or here.\nThis means that the relationship between engagement and performance can represent a good indicator of the performance culture in your organisation. While companies often assume that high-performing employees are also highly engaged, putting this assumption to the statistical test can provide surprising insights and act as an early warning sign of misalignment between performance management and employee experience."
  },
  {
    "objectID": "performance-culture-engagement.html#data-overview-methodology",
    "href": "performance-culture-engagement.html#data-overview-methodology",
    "title": "Building a Performance Culture I",
    "section": "Data Overview & Methodology",
    "text": "Data Overview & Methodology\n\nData\nThe analysis uses fully synthetic data for 1000 employees, including employee level data for performance ratings and engagement survey responses. All data was generated in R.\nThe database sample file includes the following columns:\n\nPerformanceRatings: manager ratings of each employee, for a performance review cycle, scale 1-5, where 5 means a higher performance level;\nEngagement: overall employee engagement, average of multiple questions, NPS scale 0-10;\nRewards: driver of engagement measuring employee satisfaction with compensation & rewards, average of multiple questions, NPS scale 0-10;\nAccomplishment: driver of engagement measuring employee sense of accomplishment in daily work, average of multiple questions, NPS scale 0-10;\nManagerRelations: driver of engagement measuring employee satisfaction with managerial support they receive, average of multiple questions, NPS scale 0-10;\nGoals: driver of engagement measuring employee clarity of their work goals, average of multiple questions, NPS scale 0-10;\nPeerSupport: driver of engagement measuring employee satisfaction with peer support they receive from the team, average of multiple questions, NPS scale 0-10;\n\n\n\nMethodology\nFor testing the relationship between engagement and performance I conduct a series of one-way ANOVA tests, analyzing if a more positive employee sentiment (overall Engagement and other drivers of engagement) is reported among the top performing employees."
  },
  {
    "objectID": "performance-culture-engagement.html#data-import-and-transformations",
    "href": "performance-culture-engagement.html#data-import-and-transformations",
    "title": "Building a Performance Culture I",
    "section": "Data Import and Transformations",
    "text": "Data Import and Transformations\nFirst things first: we just need to import the needed packages/ libraries and read the .csv file into our R environment.\n\n\n\n\n\n\nTipImport R packages and dataframe\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Import needed R packages\n# ------------------------------------------------------------\nlibrary(tidyverse)\nlibrary(Hmisc) \nlibrary(broom)\nlibrary(knitr)\n\n# ------------------------------------------------------------\n# Read the data\n# ------------------------------------------------------------\ndf&lt;-read_csv(\"data/performance_engagement_synthetic.csv\")\n\n\n\n\nA quick glimpse at our data shows us that all our employee engagement survey variables are looking as expected: numeric variables, on a 0-10 scale.\nTo simplify the interpretation of the ANOVA tests, we can reduce the number of performance groups from 5 to 3 groups, by joining together the 1 & 2 ratings (â€˜Low Performersâ€™) and the 4 & 5 ratings (â€˜High performersâ€™), while the performance rating equals to 3 becomes â€˜Medium performersâ€™. This decision is also supported by the overall performance distribution (18% Low performers, 52% Medium performers, 30% High performers), ensuring a big enough sample size in each group.\n\n# ------------------------------------------------------------\n# Explore the data structure\n# ------------------------------------------------------------\nglimpse(df)\n\nRows: 1,000\nColumns: 8\n$ ID                 &lt;chr&gt; \"ID83\", \"ID484\", \"ID362\", \"ID258\", \"ID116\", \"ID899\"â€¦\n$ PerformanceRatings &lt;dbl&gt; 3, 4, 5, 2, 3, 5, 3, 5, 3, 5, 2, 2, 4, 3, 3, 2, 5, â€¦\n$ Engagement         &lt;dbl&gt; 9.5, 8.0, 10.0, 4.6, 7.8, 8.6, 7.2, 7.2, 1.2, 10.0,â€¦\n$ Rewards            &lt;dbl&gt; 3.2, 7.7, 8.7, 4.2, 7.5, 8.6, 5.2, 1.2, 6.7, 5.8, 9â€¦\n$ Accomplishment     &lt;dbl&gt; 3.0, 6.6, 7.2, 10.0, 1.8, 9.8, 4.7, 9.2, 8.5, 7.5, â€¦\n$ ManagerRelations   &lt;dbl&gt; 9.0, 6.6, 7.1, 7.8, 7.6, 9.3, 6.7, 10.0, 6.5, 2.1, â€¦\n$ Goals              &lt;dbl&gt; 2.6, 8.0, 2.5, 8.5, 4.7, 2.0, 5.9, 4.2, 4.6, 7.3, 6â€¦\n$ PeerSupport        &lt;dbl&gt; 9.0, 7.8, 9.6, 5.3, 10.0, 9.5, 10.0, 9.2, 6.5, 10.0â€¦\n\n\n\n\n\n\n\n\nTipSummary for all variables\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Summary for all variables\n# ------------------------------------------------------------\nsummary(df)\n\n      ID            PerformanceRatings   Engagement        Rewards      \n Length:1000        Min.   :1.00       Min.   : 0.000   Min.   : 0.000  \n Class :character   1st Qu.:3.00       1st Qu.: 5.700   1st Qu.: 4.900  \n Mode  :character   Median :3.00       Median : 7.400   Median : 6.800  \n                    Mean   :3.19       Mean   : 7.246   Mean   : 6.556  \n                    3rd Qu.:4.00       3rd Qu.: 9.200   3rd Qu.: 8.600  \n                    Max.   :5.00       Max.   :10.000   Max.   :10.000  \n Accomplishment   ManagerRelations     Goals         PeerSupport    \n Min.   : 0.000   Min.   : 0.000   Min.   : 0.000   Min.   : 0.500  \n 1st Qu.: 5.500   1st Qu.: 4.900   1st Qu.: 4.500   1st Qu.: 6.775  \n Median : 7.200   Median : 6.800   Median : 6.400   Median : 8.400  \n Mean   : 7.037   Mean   : 6.622   Mean   : 6.314   Mean   : 7.974  \n 3rd Qu.: 9.000   3rd Qu.: 8.625   3rd Qu.: 8.300   3rd Qu.: 9.900  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.000  \n\n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Understand the performance distribution\n# ------------------------------------------------------------\ndf |&gt;\n  count(PerformanceRatings) |&gt;\n  mutate(Percentage = n / sum(n) * 100) |&gt;\n  knitr::kable(\n    col.names = c(\"Performance rating\", \"Count\", \"Percentage (%)\"),\n    digits = 1,\n    caption = \"Table 1: Distribution of performance ratings\")\n\n\n\nTable 1: Distribution of performance ratings\n\n\nPerformance rating\nCount\nPercentage (%)\n\n\n\n\n1\n50\n5\n\n\n2\n130\n13\n\n\n3\n520\n52\n\n\n4\n180\n18\n\n\n5\n120\n12\n\n\n\n\n\nOne important step for an ANOVA test is to clearly define the groups among which we will be doing the comparisons. In R, the easiest way to do this is to convert the variable of interest â€˜Performanceâ€™ into a factor. We can also quickly check that the re-coding worked as intended.\n\n\n\n\n\n\nTipRecode performance ratings (using ifelse()) and validate re-coding\n\n\n\n\n\n\n# ------------------------------------------------------------\n#  Re-code performance: form 1 to 5 into 3 performance categories\n# ------------------------------------------------------------\ndf$Performance &lt;- ifelse(df$PerformanceRatings %in% c(1, 2), \"Low performers\",\n                       ifelse(df$PerformanceRatings == 3, \"Medium performers\", \"High performers\"))\n\ndf$Performance &lt;- factor(df$Performance, levels = c(\"Low performers\", \"Medium performers\", \"High performers\"))\n\n\n# ------------------------------------------------------------\n# Validate the re-coding\n# ------------------------------------------------------------\ndf |&gt;\n  select(PerformanceRatings, Performance) |&gt;\n  head(5)\n\n# A tibble: 5 Ã— 2\n  PerformanceRatings Performance      \n               &lt;dbl&gt; &lt;fct&gt;            \n1                  3 Medium performers\n2                  4 High performers  \n3                  5 High performers  \n4                  2 Low performers   \n5                  3 Medium performers"
  },
  {
    "objectID": "performance-culture-engagement.html#data-analysis-results",
    "href": "performance-culture-engagement.html#data-analysis-results",
    "title": "Building a Performance Culture I",
    "section": "Data Analysis & Results",
    "text": "Data Analysis & Results\n\nDescriptive Statistics\nWhile in this case the purpose and methods of the analysis were pre-defined, it can never be a bad idea to explore your data in order to understand it and notice any unexpected pattern.\nThe average engagement scores by performance groups shows that:\n\nFor Overall Engagement and Accomplishment, engagement increases with Performance;\nFor Goals and Peer Support, the averages are quite similar across Low, Medium and High performers;\nLow performers are on average more satisfied with their Manager Relation, compared to the other performance groups;\nHigh performers are on average more satisfied with their Rewards, compared to the employees in the other performance groups.\n\n\n\nCode\n# ------------------------------------------------------------\n# Build 2 helper variables: 1st to  use Performance as the grouping variable and 2nd to select all the drivers of engagement\n# ------------------------------------------------------------\ngroup_var &lt;- \"Performance\"\n\ndrivers &lt;- c(\n  \"Engagement\",\n  \"Rewards\",\n  \"Accomplishment\",\n  \"ManagerRelations\",\n  \"Goals\",\n  \"PeerSupport\")\n\n# ------------------------------------------------------------\n# Create and format Table 2: Descriptive Statistics (N, Mean, SD) by Performance group\n# ------------------------------------------------------------\ndesc_table &lt;- df |&gt;\n  select(Performance, all_of(drivers)) |&gt;\n  pivot_longer(all_of(drivers), names_to = \"Driver\", values_to = \"Score\") |&gt;\n  group_by(Driver, Performance) |&gt;\n  summarise(\n    N = sum(!is.na(Score)),\n    Mean = mean(Score, na.rm = TRUE),\n    SD = sd(Score, na.rm = TRUE),\n    .groups = \"drop\") |&gt;\n  arrange(Driver, Performance)\n\nkable(\n  desc_table,\n  digits = 2,\n  caption = \"Table 2: Descriptive statistics (N, Mean, SD) by Performance group\")\n\n\n\nTable 2: Descriptive statistics (N, Mean, SD) by Performance group\n\n\nDriver\nPerformance\nN\nMean\nSD\n\n\n\n\nAccomplishment\nLow performers\n180\n5.62\n2.23\n\n\nAccomplishment\nMedium performers\n520\n7.03\n2.19\n\n\nAccomplishment\nHigh performers\n300\n7.90\n1.94\n\n\nEngagement\nLow performers\n180\n6.41\n2.39\n\n\nEngagement\nMedium performers\n520\n7.23\n2.17\n\n\nEngagement\nHigh performers\n300\n7.78\n1.98\n\n\nGoals\nLow performers\n180\n6.32\n2.57\n\n\nGoals\nMedium performers\n520\n6.40\n2.55\n\n\nGoals\nHigh performers\n300\n6.16\n2.54\n\n\nManagerRelations\nLow performers\n180\n7.33\n2.30\n\n\nManagerRelations\nMedium performers\n520\n6.47\n2.46\n\n\nManagerRelations\nHigh performers\n300\n6.46\n2.35\n\n\nPeerSupport\nLow performers\n180\n7.91\n2.05\n\n\nPeerSupport\nMedium performers\n520\n7.93\n1.95\n\n\nPeerSupport\nHigh performers\n300\n8.08\n1.92\n\n\nRewards\nLow performers\n180\n6.38\n2.43\n\n\nRewards\nMedium performers\n520\n6.25\n2.52\n\n\nRewards\nHigh performers\n300\n7.19\n2.34\n\n\n\n\n\nIn the next section we will test if any of these differences are statistically significant or simply due to random variation.\n\n\nANOVA: Interpreting the results\nTo interpret the results of a one-way ANOVA appropriately, three aspects should be considered:\n\n\nthe distribution of the outcome variable across the comparison groups, to understand the underlying group patterns (chart below);\n\n\nthe overall ANOVA test statistic, which assesses whether any statistically significant differences exist between group means (Table 3);\n\n\nthe post-hoc pairwise comparisons, which identify where those differences stand and confirm whether the observed effects align with the expected group averages (Table 4);.\n\n\n\n\nOverall Engagement vs Performance\n\n\n\n\n\n\nTipUsing ggplot2 to create boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Overall Engagement vs Performance: Building a boxplot with ggplot\n# ------------------------------------------------------------\nchart1&lt;-df|&gt;\n  filter(!is.na(Performance)) |&gt; #ensures we remove any missing values\n  filter(!is.na(Engagement)) |&gt; #ensures we remove any missing values\n  ggplot(aes(y=Engagement, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.3, size=1.2, position = position_dodge())+\n  labs(x=\"Performance Group\", y=\"Engagement Score\", caption=(\"Number of observations: 1000\")) +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Overall Engagement by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart1\n\n\n\n\n\nOverall Engagement by Performance Group (click the chart to enlarge)\n\n\n\n\nFor the current dataset, Engagement differs significantly across performance groups (F(2,997)=22.50, p&lt;.001, Î·Â²=0.04). High performers report higher engagement than both medium and low performers, with all pairwise differences statistically significant. However, the effect size is modest, suggesting engagement explains only a small share of performance differences.\n\n\nCode\n# ------------------------------------------------------------\n# Create a summary table for ANOVA tests\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Create a helper object for the summary table: eta-squared from aov object (one-way ANOVA)\n# ------------------------------------------------------------\neta_sq_oneway &lt;- function(fit) {\n  a &lt;- summary(fit)[[1]]\n  ss_effect &lt;- a[[\"Sum Sq\"]][1]\n  ss_total  &lt;- sum(a[[\"Sum Sq\"]], na.rm = TRUE)\n  ss_effect / ss_total\n}\n\n# ------------------------------------------------------------\n# Create and format Table 3: ANOVA results (Driver-by-driver)\n# ------------------------------------------------------------\nanova_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  \n  a &lt;- summary(fit)[[1]]\n  \n  tibble(\n    Driver = d,\n    df1 = a$Df[1],\n    df2 = a$Df[2],\n    F = a$`F value`[1],\n    p_value = a$`Pr(&gt;F)`[1],\n    eta_sq = eta_sq_oneway(fit)\n  )\n})) %&gt;%\n  arrange(p_value)\n\nkable(\n  anova_table,\n  digits = 4,\n  caption = \"Table 3: One-way ANOVA results: Performance group differences by driver\")\n\n\n\nTable 3: One-way ANOVA results: Performance group differences by driver\n\n\nDriver\ndf1\ndf2\nF\np_value\neta_sq\n\n\n\n\nAccomplishment\n2\n997\n64.7951\n0.0000\n0.1150\n\n\nEngagement\n2\n997\n22.4963\n0.0000\n0.0432\n\n\nRewards\n2\n997\n14.7456\n0.0000\n0.0287\n\n\nManagerRelations\n2\n997\n9.4776\n0.0001\n0.0187\n\n\nGoals\n2\n997\n0.8058\n0.4470\n0.0016\n\n\nPeerSupport\n2\n997\n0.6747\n0.5095\n0.0014\n\n\n\n\n\nPerceived Accomplishment shows the strongest differences by performance group (F(2,997)=64.80, p&lt;.001, Î·Â²=0.12). High performers report substantially higher accomplishment than medium and low performers, and medium performers also score higher than low performers.This represents a moderate effect, indicating accomplishment is closely associated with performance outcomes.\nManager relations vary significantly by performance group (F(2,997)=9.48, p&lt;.001, Î·Â²=0.02). Low performers report better manager relations than both medium and high performers, while no meaningful difference is observed between medium and high performers.Overall, the effect is small, suggesting limited practical impact despite statistical significance.\nPerceptions of Rewards differ significantly across performance groups (F(2,997)=14.75, p&lt;.001, Î·Â²=0.03). High performers report higher rewards than both low and medium performers, while no significant difference is observed between low and medium performers. The effect size is also small.\n\n\nCode\n# ------------------------------------------------------------\n# Create and format Table 4: Tukey HSD post-hoc results (all drivers)\n# ------------------------------------------------------------\ntukey_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  tuk &lt;- TukeyHSD(fit)\n  \n  broom::tidy(tuk) %&gt;%\n    mutate(\n      Driver = d,\n      Comparison = contrast,\n      Difference = estimate,\n      CI_Lower = conf.low,\n      CI_Upper = conf.high,\n      p_adj = adj.p.value\n    ) %&gt;%\n    select(Driver, Comparison, Difference, CI_Lower, CI_Upper, p_adj) %&gt;%\n    arrange(p_adj)\n}))\n\nkable(\n  tukey_table,\n  digits = 4,\n  caption = \"Table 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\"\n)\n\n\n\nTable 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\n\n\n\n\n\n\n\n\n\n\nDriver\nComparison\nDifference\nCI_Lower\nCI_Upper\np_adj\n\n\n\n\nEngagement\nHigh performers-Low performers\n1.3647\n0.8867\n1.8426\n0.0000\n\n\nEngagement\nMedium performers-Low performers\n0.8136\n0.3752\n1.2520\n0.0000\n\n\nEngagement\nHigh performers-Medium performers\n0.5511\n0.1835\n0.9186\n0.0013\n\n\nRewards\nHigh performers-Medium performers\n0.9453\n0.5283\n1.3623\n0.0000\n\n\nRewards\nHigh performers-Low performers\n0.8182\n0.2760\n1.3605\n0.0012\n\n\nRewards\nMedium performers-Low performers\n-0.1271\n-0.6244\n0.3703\n0.8203\n\n\nAccomplishment\nHigh performers-Low performers\n2.2807\n1.8104\n2.7510\n0.0000\n\n\nAccomplishment\nMedium performers-Low performers\n1.4058\n0.9745\n1.8372\n0.0000\n\n\nAccomplishment\nHigh performers-Medium performers\n0.8748\n0.5132\n1.2365\n0.0000\n\n\nManagerRelations\nMedium performers-Low performers\n-0.8547\n-1.3417\n-0.3678\n0.0001\n\n\nManagerRelations\nHigh performers-Low performers\n-0.8680\n-1.3989\n-0.3371\n0.0004\n\n\nManagerRelations\nHigh performers-Medium performers\n-0.0133\n-0.4215\n0.3950\n0.9968\n\n\nGoals\nHigh performers-Medium performers\n-0.2346\n-0.6686\n0.1993\n0.4131\n\n\nGoals\nHigh performers-Low performers\n-0.1563\n-0.7206\n0.4080\n0.7923\n\n\nGoals\nMedium performers-Low performers\n0.0783\n-0.4393\n0.5959\n0.9329\n\n\nPeerSupport\nHigh performers-Medium performers\n0.1493\n-0.1843\n0.4830\n0.5451\n\n\nPeerSupport\nHigh performers-Low performers\n0.1747\n-0.2592\n0.6085\n0.6119\n\n\nPeerSupport\nMedium performers-Low performers\n0.0253\n-0.3726\n0.4233\n0.9878\n\n\n\n\n\n\n\nVisualising the results\n\n\n\n\n\n\nTipUsing ggplot2 to create a grid chart\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Create and format a grid chart with 6 views:  95% confidence interval plots (Engagement + Engagement drivers) + ANOVA p-values + Î·Â²\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Build a long format dataframe (via pivot_longer()) for faceting\n# ------------------------------------------------------------\ndf_long &lt;- df %&gt;%\n  select(Performance, all_of(drivers)) %&gt;%\n  pivot_longer(\n    cols = all_of(drivers),\n    names_to = \"Driver\",\n    values_to = \"Score\"\n  ) %&gt;%\n  filter(!is.na(Performance), !is.na(Score)) %&gt;%\n  mutate(Driver = factor(Driver, levels = drivers))\n\n# ------------------------------------------------------------\n# Build labels from previous ANOVA summary table (p + eta-squared)\n# ------------------------------------------------------------\nstats_labels &lt;- anova_table %&gt;%\n  select(Driver, p_value, eta_sq) %&gt;%\n  mutate(\n    p_txt = ifelse(\n      p_value &lt; 0.001,\n      \"p &lt; 0.001\",\n      paste0(\"p = \", formatC(p_value, format = \"f\", digits = 3))\n    ),\n    eta_txt = paste0(\"\\u03b7\\u00b2 = \", formatC(eta_sq, format = \"f\", digits = 3)),\n    stat_label = paste0(\"ANOVA \", p_txt, \"  |  \", eta_txt),\n    x = 1\n  )\n\n# ------------------------------------------------------------\n# Build a helper object for label positions per facet, so labels appear near the top of each panel\n# ------------------------------------------------------------\n\ny_pos &lt;- df_long %&gt;%\n  group_by(Driver) %&gt;%\n  summarise(\n    y = max(Score, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nstats_plot &lt;- left_join(stats_labels, y_pos, by = \"Driver\")\n\n# ------------------------------------------------------------\n# Create and format the actual grid plot\n# ------------------------------------------------------------\nchart_grid &lt;- ggplot(df_long, aes(x = Performance, y = Score, colour = Performance)) +\n  stat_summary(fun = \"mean\", geom = \"point\", size = 1.8) +\n  stat_summary(\n    fun.data = mean_cl_boot,\n    geom = \"errorbar\",\n    width = 0.25,\n    size = 0.9\n  ) +\n  facet_wrap(~ Driver, ncol = 3, scales = \"free_y\") +\n  geom_text(\n    data = stats_plot,\n    aes(x = x, y = y, label = stat_label),\n    inherit.aes = FALSE,\n    hjust = 0,\n    vjust = 1,\n    size = 3.3,\n    colour = \"grey20\"\n  ) +\n  labs(\n    x = \"Performance Group\",\n    y = \"Score\",\n    caption = \"Note: Points show group means; error bars show 95% bootstrap confidence intervals.\"\n  ) +\n  ggtitle(\"Overall Engagement and Engagement Drivers by Performance Group\", subtitle = \"One-way ANOVA (Score ~ Performance) per panel. Effect size reported as \\u03b7\\u00b2.\") +\n  theme_bw() +\n  theme(\n    strip.text = element_text(size = 12, face = \"bold\"),\n    axis.text.x = element_text(size = 10, face = \"italic\", angle = 15, hjust = 1),\n    axis.title = element_text(size = 13, face = \"bold\"),\n    plot.caption = element_text(size = 9, colour = \"grey30\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\") +\n  scale_colour_brewer(palette = \"Set2\")+\n  scale_x_discrete(labels = c(\n    \"Low performers\" = \"Low\",\n    \"Medium performers\" = \"Medium\",\n    \"High performers\" = \"High\"))\n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart_grid\n\n\n\n\n\nOverall Engagement and Engagement Drivers by Performance Group (click the chart to enlarge)"
  },
  {
    "objectID": "performance-culture-engagement.html#insights-and-recommendations",
    "href": "performance-culture-engagement.html#insights-and-recommendations",
    "title": "Building a Performance Culture I",
    "section": "Insights and Recommendations",
    "text": "Insights and Recommendations"
  },
  {
    "objectID": "performance-culture-rewards.html",
    "href": "performance-culture-rewards.html",
    "title": "Building a Performance Culture II",
    "section": "",
    "text": "Are your top performers fairly rewarded?\n\n\n\n\n\n\nNote\n\n\n\nðŸš§ Content in progress\nThis case study will look at reward differentiation, fairness, and performance signals, highlighting how data can inform compensation decisions responsibly.\nAll examples will rely on synthetic data.\n\n\nUpdate test - Jan 2026"
  },
  {
    "objectID": "tenure-retention-trends.html",
    "href": "tenure-retention-trends.html",
    "title": "Understanding Average Tenure and Retention Rate Trends",
    "section": "",
    "text": "What do tenure and retention metrics really tell us over time?\n\n\n\n\n\n\nNote\n\n\n\nðŸš§ Content in progress\nThis analysis will explore how average tenure and retention rates evolve, and how misinterpretation can lead to misleading conclusions.\nAll data will be synthetic."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there, Iâ€™m George-Alexandru Matu and I currently work as a Senior People Data Analyst.\nIâ€™ve decided to build The People Data Notebook for three main reasons:\nMy trajectory towards people analytics was somewhat atypical, as I have a PhD in Sociology and I initially dreamed of becoming a university professor. Although I truly enjoyed teaching and deep-diving into interesting research topics, I eventually decided that academia was not the right fit for me. People analytics felt like a natural career transition, as it allows me to continue analyzing survey responses, performing statistical analyses, working with qualitative data, and writing concise, actionable reports.\nAs many other people data analysts, I work at the intersection of data analytics, data science, data governance, and decision-making.\nIâ€™m originally from Romania but I currently live in Madrid, with my loving partner, Ada, and our cat, Vlahuta. Outside of work, I love to play chess, cook and take long walks."
  },
  {
    "objectID": "about.html#certifications",
    "href": "about.html#certifications",
    "title": "About",
    "section": "Certifications",
    "text": "Certifications\n\n\n \n\nData Analyst with R (DataCamp)\n\n\n\n\n \n\nData Analyst in SQL (DataCamp)\n\n\n\n\n \n\nAssociate Data Scientist in R (DataCamp)\n\n\n\n\n \n\nGoogle Data Analytics (Coursera)\n\n\n\n\n \n\nExplore & Analyze Data (Tableau)\n\n\n\n\n \n\nConnect & Transform Data (Tableau)\n\n\n\n\n \n\nCreate Views & Dashboards (Tableau)\n\n\n\n\n \n\nPublish & Manage Content (Tableau)"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\n\nEmail me\nConnect on LinkedIn"
  },
  {
    "objectID": "recruitment-capacity.html",
    "href": "recruitment-capacity.html",
    "title": "Recruitment Capacity Model",
    "section": "",
    "text": "How many recruiters do you need for each department?\n\n\n\n\n\n\nNote\n\n\n\nðŸš§ Content in progress\nThis project will demonstrate how to model recruitment capacity using hiring demand, recruitment productivity and headcount trends.\nAll datasets will be synthetic and illustrative."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "This page contains a selection of people analytics case studiesâ€¦.."
  },
  {
    "objectID": "projects.html#case-studies",
    "href": "projects.html#case-studies",
    "title": "Projects",
    "section": "Case studies",
    "text": "Case studies\n\n\nBuilding a Performance Culture I\nAre your top performers more engaged?\nBuilding a Performance Culture II\nAre your top performers fairly rewarded?"
  },
  {
    "objectID": "projects.html#coming-soon",
    "href": "projects.html#coming-soon",
    "title": "Projects",
    "section": "Coming soon",
    "text": "Coming soon\n\nAnalyzing Employee Engagement Surveys: Main Drivers of Engagement\nHow do you choose action areas when all survey themes seem important?\nRecruitment Capacity Model\nHow many recruiters do you need for each department?\nUnderstanding Average Tenure and Retention Rate Trends\nExploring how tenure distributions and retention metrics evolve over time.\nVisualising Workforce Density\nMapping workforce distribution by country and nationality using geospatial data."
  },
  {
    "objectID": "workforce-density-maps.html",
    "href": "workforce-density-maps.html",
    "title": "Visualising Workforce Density",
    "section": "",
    "text": "Where does the workforce come from, and how can geography add context to people data?\n\n\n\n\n\n\nNote\n\n\n\nðŸš§ Content in progress\nThis project will showcase how geospatial visualisations (e.g.Â maps) can be used to explore workforce distribution by country and nationality.\nAll examples will be built using synthetic data."
  },
  {
    "objectID": "engagement-drivers.html",
    "href": "engagement-drivers.html",
    "title": "Analyzing Employee Engagement Surveys: Main Drivers of Engagement",
    "section": "",
    "text": "How do you choose action areas when all survey themes seem important?\n\n\n\n\n\n\nNote\n\n\n\nðŸš§ Content in progress\nThis case study will explore how to identify meaningful engagement drivers while avoiding common analytical traps.\nAll examples will use synthetic data created for demonstration purposes."
  },
  {
    "objectID": "performance-culture-engagement.html#conclusion-recommendations",
    "href": "performance-culture-engagement.html#conclusion-recommendations",
    "title": "Building a Performance Culture I",
    "section": "Conclusion & Recommendations",
    "text": "Conclusion & Recommendations\n\nConclusion\nThe results provide evidence of a performance culture in which higher performance is associated with higher engagement and a stronger sense of accomplishment.\nHowever, the findings also point to potential imbalances. While top performers are rewarded more, medium performers (representing 52% of the workforce) do not appear to be clearly differentiated from low performers in terms of rewards. In addition, lower-performing employees report more positive manager relations, which may indicate that managerial attention is disproportionately focused on performance remediation rather than sustained engagement across all performance levels.\n\n\nRecommendations\n\nSustain engagement and accomplishment among top performers: The strong association between performance, engagement, and accomplishment suggests that existing practices supporting autonomy, mastery, and meaningful work should be maintained and reinforced for high performers.\nRe-examine reward differentiation for medium performers: The lack of meaningful reward differences between low and medium performers may weaken motivation in the middle of the performance distribution. Introducing clearer performance-linked recognition for medium performers could help prevent disengagement and performance stagnation.\nBalance managerial attention across performance groups: While supporting low performers is important, the stronger manager relations reported by low performers suggest a potential over-correction. Managers should be encouraged to invest equally in coaching and development conversations with medium and high performers to sustain long-term engagement.\nUse engagement metrics as an early warning indicator: Given the modest but consistent link between engagement and performance, monitoring engagement trends by performance group can help identify emerging misalignments between performance management practices and employee experience before they affect outcomes."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The People Data Notebook",
    "section": "",
    "text": "This notebook showcases how employee and workforce data can be used to support better decisions about the most valuable resource of any organisation: its people.\nHR is often seen only as a support function, with an inherent desire to create useless administrative workload for the entire organisation and where decisions are driven by opinion rather than evidence. People analytics challenges these assumptions and shows how data-driven people decisions can be beneficial for both the organisations and the employees.\nIf you are new to the field, it is worth mentioning that there are a lot of useful People Analytics & HR resources out there. See for example the Academy to Innovate HR blog or the Data Driven HR Monthly newsletter, as well as some great books that showcase actual data projects in the field of people analytics:\nWhile designed as data analytics portfolio, through this website I hope to share a few practical examples of real HR business questions, contributing to the popularization of people analytics for better people decisions."
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "The People Data Notebook",
    "section": "Featured projects",
    "text": "Featured projects\n\n\n\nBuilding a Performance Culture I\nAre your top performers more engaged?\n\n\n\nBuilding a Performance Culture II\nAre your top performers fairly rewarded?"
  },
  {
    "objectID": "index.html#comming-soon",
    "href": "index.html#comming-soon",
    "title": "The People Data Notebook",
    "section": "Comming Soon",
    "text": "Comming Soon\n\n\n\nAnalyzing Employee Engagement Surveys: Main Drivers of Engagement\nHow do you choose action areas when all survey themes seem important?\n\n\n\nRecruitment Capacity Model\nHow many recruiters do you need for each department?"
  },
  {
    "objectID": "performance-culture-rewards.html#executive-summary",
    "href": "performance-culture-rewards.html#executive-summary",
    "title": "Building a Performance Culture II",
    "section": "Executive summary",
    "text": "Executive summary\nThis case study provides step-by-step instructions in R on how to test whether the outcomes of an organisationâ€™s compensation review process follow the â€˜pay-for-performance principleâ€™, using salary increases, equity awards, and total compensation increase as key indicators."
  },
  {
    "objectID": "performance-culture-rewards.html#context-business-question",
    "href": "performance-culture-rewards.html#context-business-question",
    "title": "Building a Performance Culture II",
    "section": "Context & Business Question",
    "text": "Context & Business Question\n(Annual) compensation review cycles play a critical role in how organisations attract and retain top talent. Beyond adjusting salaries in response to inflation and competitive pressures on the labour market, these cycles provide an opportunity to address any legacy issues, such as internal inequities, or employees being positioned too low within their salary ranges.\nEqually important, the Compensation Review process is a key mechanism for reinforcing a performance culture within the organisation, by differentiating rewards based on employee performance. Therefore, throughout the comp review, one particularly relevant test for the entire process is to assess whether compensation outcomes vary systematically with performance levels.\nBusiness question: Do employees with higher performance ratings receive, on average, higher salary increases, equity awards, and total compensation growth compared to lower-performing peers?"
  },
  {
    "objectID": "performance-culture-rewards.html#data-overview-methodology",
    "href": "performance-culture-rewards.html#data-overview-methodology",
    "title": "Building a Performance Culture II",
    "section": "Data Overview & Methodology",
    "text": "Data Overview & Methodology\n\nData\nThe analysis uses fully synthetic data for 1000 employees, including employee level data for performance ratings and compensation review outcomes. All data was generated in R.\nThe database sample file includes the following columns:\n\nPerformanceRatings: manager ratings of each employee, for a performance review cycle, scale 1-5, where 5 means a higher performance level;\nSalaryIncrease: percentage (%) increase of the annual salary for each employee (before vs.Â after comp review);\nEquityIncrease: percentage (%) increase of the equity or stocks awarded for each employee (before vs.Â after comp review);\nTotalCompIncrease: annualized percentage (%) increase of the total compensation (salary + equity) for each employee (before vs.Â after comp review). Note, the equity awarded has a 4 year vesting period, as per the industry standard practice, so in the calculation of the Annualized Total Comp(%) increase, the Equity Increase is divided by 4.\nCompaRatioBefore: employeeâ€™s compa-ratio prior to the compensation review cycle\nCompaRatioAfter: employeeâ€™s compa-ratio following the compensation review cycle, calculated based on the updated base salary after the applied salary increase.\nNote: The compa-ratio represents the relationship between an employeeâ€™s base salary and the midpoint of the corresponding salary range. A value of 1.00 indicates alignment with the market median for the role, while values below or above 1.00 indicate positioning below or above the range midpoint, respectively. Compa-ratio is based on base salary only and does not reflect equity or other non-cash compensation components.\n\n\n\nMethodology\nFor testing the relationship between performance and compensation review outcomes, I conduct a series of one-way ANOVA tests, analyzing if a higher percentage increase in salary, equity or total compensation is reported among the top performing employees.\nAt the same time, to evaluate how compensation decisions affect employeesâ€™ positioning within their salary ranges, I analyze changes in compa-ratio before and after the compensation review cycle. Specifically, I compute within-employee compa-ratio deltas and assess whether the average magnitude of these changes differs across performance groups, using one-way ANOVA on compa-ratio changes complemented by paired comparisons."
  },
  {
    "objectID": "performance-culture-rewards.html#data-import-and-transformations",
    "href": "performance-culture-rewards.html#data-import-and-transformations",
    "title": "Building a Performance Culture II",
    "section": "Data Import and Transformations",
    "text": "Data Import and Transformations\nThe first step is to import the needed R packages read the data file into our R environment.\n\n\n\n\n\n\nTipImport R packages and dataframe\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Import needed R packages\n# ------------------------------------------------------------\nlibrary(tidyverse) # \nlibrary(Hmisc) \nlibrary(broom)\nlibrary(knitr)\nlibrary(scales)\n\n# ------------------------------------------------------------\n# Read the data\n# ------------------------------------------------------------\ndf_comp&lt;-read_csv(\"data/performance_compensation_synthetic.csv\")\n\n\n\n\nWe can take a quick look at our data using glimpse() or summary(). All variables are looking as expected: numeric variables, with no extremely big outliers (see histograms). While the maximum equity increase reaches 75%, such values can reasonably occur in compensation reviews, where equity is frequently used as a targeted incentive for high performers or key talent. In addition, we can see that a significant number of employees show a 0% increase for salary, equity of total compensation, which is common in compensation review cycles due to eligibility criteria or imposed performance thresholds.\n\n\nCode\n# ------------------------------------------------------------\n# Explore the data structure\n# ------------------------------------------------------------\nglimpse(df_comp)\n\n\nRows: 1,000\nColumns: 7\n$ ID                 &lt;chr&gt; \"ID83\", \"ID484\", \"ID362\", \"ID258\", \"ID116\", \"ID899\"â€¦\n$ PerformanceRatings &lt;dbl&gt; 3, 4, 5, 2, 3, 5, 3, 5, 3, 5, 2, 2, 4, 3, 3, 2, 5, â€¦\n$ SalaryIncrease     &lt;dbl&gt; 0.038, 0.075, 0.050, 0.000, 0.057, 0.058, 0.066, 0.â€¦\n$ EquityIncrease     &lt;dbl&gt; 0.000, 0.222, 0.347, 0.000, 0.000, 0.202, 0.000, 0.â€¦\n$ TotalCompIncrease  &lt;dbl&gt; 0.038, 0.131, 0.137, 0.000, 0.057, 0.109, 0.066, 0.â€¦\n$ CompaRatioBefore   &lt;dbl&gt; 0.928, 0.921, 0.947, 1.066, 1.003, 0.987, 0.858, 0.â€¦\n$ CompaRatioAfter    &lt;dbl&gt; 0.964, 0.990, 0.995, 1.066, 1.061, 1.044, 0.914, 0.â€¦\n\n\n\n\n\n\n\n\nTipSummary and checking outliers (histograms)\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Summary for all variables\n# ------------------------------------------------------------\nsummary(df_comp)\n\n      ID            PerformanceRatings SalaryIncrease   EquityIncrease  \n Length:1000        Min.   :1.00       Min.   :0.0000   Min.   :0.0000  \n Class :character   1st Qu.:3.00       1st Qu.:0.0370   1st Qu.:0.0000  \n Mode  :character   Median :3.00       Median :0.0520   Median :0.1530  \n                    Mean   :3.19       Mean   :0.0481   Mean   :0.1628  \n                    3rd Qu.:4.00       3rd Qu.:0.0690   3rd Qu.:0.2672  \n                    Max.   :5.00       Max.   :0.1100   Max.   :0.7520  \n TotalCompIncrease CompaRatioBefore CompaRatioAfter\n Min.   :0.00000   Min.   :0.7000   Min.   :0.700  \n 1st Qu.:0.04900   1st Qu.:0.9000   1st Qu.:0.945  \n Median :0.09000   Median :0.9860   Median :1.034  \n Mean   :0.08881   Mean   :0.9822   Mean   :1.030  \n 3rd Qu.:0.12800   3rd Qu.:1.0660   3rd Qu.:1.121  \n Max.   :0.26900   Max.   :1.2000   Max.   :1.300  \n\n# ------------------------------------------------------------\n# Histograms\n# ------------------------------------------------------------\npar(mfrow = c(1, 3))  # 1x3 grid\n\nhist(df_comp$SalaryIncrease, breaks = 15,\n     main = \"Salary Increase (%)\")\n\nhist(df_comp$EquityIncrease, breaks = 15,\n     main = \"Equity Increase (%)\")\n\nhist(df_comp$TotalCompIncrease, breaks = 15,\n     main = \"Total Comp Increase (%)\")\n\n\n\n\n\n\n\n\n\n\n\nTo simplify the interpretation of the ANOVA tests,one option is to reduce the number of performance groups from 5 to 3 groups, by joining together the 1 & 2 ratings (â€˜Low Performersâ€™) and the 4 & 5 ratings (â€˜High performersâ€™), while the performance rating equals to 3 becomes â€˜Medium performersâ€™. This decision is also supported by the overall performance distribution (Table 1), ensuring a big enough sample size in each group.\nHowever, in order to properly test that rewards are increasing with performance we might want to differentiate more clearly the reward distribution among top-performers (see the Analysis & Results section below) .\n\n\nCode\n# ------------------------------------------------------------\n# Understand the performance distribution\n# ------------------------------------------------------------\ndf_comp |&gt;\n  count(PerformanceRatings) |&gt;\n  mutate(Percentage = n / sum(n) * 100) |&gt;\n  knitr::kable(\n    col.names = c(\"Performance rating\", \"Count\", \"Percentage (%)\"),\n    digits = 1,\n    caption = \"Table 1: Distribution of performance ratings\")\n\n\n\nTable 1: Distribution of performance ratings\n\n\nPerformance rating\nCount\nPercentage (%)\n\n\n\n\n1\n50\n5\n\n\n2\n130\n13\n\n\n3\n520\n52\n\n\n4\n180\n18\n\n\n5\n120\n12\n\n\n\n\n\nOne extra-step is to convert the grouping variable â€˜Performanceâ€™ into a factor. We can also quickly check that the re-coding worked as intended.\n\n\n\n\n\n\nTipRecode performance ratings (using case_when()) and validate re-coding\n\n\n\n\n\n\n# ------------------------------------------------------------\n#  Re-code performance: form 1 to 5 into 3 performance categories\n# ------------------------------------------------------------\ndf_comp &lt;- df_comp |&gt;\n  mutate(Performance = case_when(PerformanceRatings %in% c(1, 2) ~ \"Low performers\",\n                                 PerformanceRatings == 3         ~ \"Medium performers\",\n                                 PerformanceRatings %in% c(4, 5) ~ \"High performers\"))\n\ndf_comp$Performance &lt;- factor(df_comp$Performance, levels = c(\"Low performers\", \"Medium performers\", \"High performers\"))\n\n\n# ------------------------------------------------------------\n# Validate the re-coding\n# ------------------------------------------------------------\ndf_comp |&gt;\n  select(PerformanceRatings, Performance) |&gt;\n  head(5)\n\n# A tibble: 5 Ã— 2\n  PerformanceRatings Performance      \n               &lt;dbl&gt; &lt;fct&gt;            \n1                  3 Medium performers\n2                  4 High performers  \n3                  5 High performers  \n4                  2 Low performers   \n5                  3 Medium performers"
  },
  {
    "objectID": "performance-culture-rewards.html#data-analysis-results",
    "href": "performance-culture-rewards.html#data-analysis-results",
    "title": "Building a Performance Culture II",
    "section": "Data Analysis & Results",
    "text": "Data Analysis & Results\n\nDescriptive Statistics\nWhile in this case the purpose and methods of the analysis were pre-defined, it can never be a bad idea to explore your data in order to understand it and notice any unexpected pattern.\nThe average engagement scores by performance groups shows that:\n\nFor Overall Engagement and Accomplishment, engagement increases with Performance;\nFor Goals and Peer Support, the averages are quite similar across Low, Medium and High performers;\nLow performers are on average more satisfied with their Manager Relation, compared to the other performance groups;\nHigh performers are on average more satisfied with their Rewards, compared to the employees in the other performance groups.\n\n\n\nCode\n# ------------------------------------------------------------\n# Build 2 helper variables: 1st to  use Performance as the grouping variable and 2nd to select all the drivers of engagement\n# ------------------------------------------------------------\ngroup_var &lt;- \"Performance\"\n\ndrivers &lt;- c(\n  \"Engagement\",\n  \"Rewards\",\n  \"Accomplishment\",\n  \"ManagerRelations\",\n  \"Goals\",\n  \"PeerSupport\")\n\n# ------------------------------------------------------------\n# Create and format Table 2: Descriptive Statistics (N, Mean, SD) by Performance group\n# ------------------------------------------------------------\ndesc_table &lt;- df |&gt;\n  select(Performance, all_of(drivers)) |&gt;\n  pivot_longer(all_of(drivers), names_to = \"Driver\", values_to = \"Score\") |&gt;\n  group_by(Driver, Performance) |&gt;\n  summarise(\n    N = sum(!is.na(Score)),\n    Mean = mean(Score, na.rm = TRUE),\n    SD = sd(Score, na.rm = TRUE),\n    .groups = \"drop\") |&gt;\n  arrange(Driver, Performance)\n\nkable(\n  desc_table,\n  digits = 2,\n  caption = \"Table 2: Descriptive statistics (N, Mean, SD) by Performance group\")\n\n\n\nTable 2: Descriptive statistics (N, Mean, SD) by Performance group\n\n\nDriver\nPerformance\nN\nMean\nSD\n\n\n\n\nAccomplishment\nLow performers\n180\n5.62\n2.23\n\n\nAccomplishment\nMedium performers\n520\n7.03\n2.19\n\n\nAccomplishment\nHigh performers\n300\n7.90\n1.94\n\n\nEngagement\nLow performers\n180\n6.41\n2.39\n\n\nEngagement\nMedium performers\n520\n7.23\n2.17\n\n\nEngagement\nHigh performers\n300\n7.78\n1.98\n\n\nGoals\nLow performers\n180\n6.32\n2.57\n\n\nGoals\nMedium performers\n520\n6.40\n2.55\n\n\nGoals\nHigh performers\n300\n6.16\n2.54\n\n\nManagerRelations\nLow performers\n180\n7.33\n2.30\n\n\nManagerRelations\nMedium performers\n520\n6.47\n2.46\n\n\nManagerRelations\nHigh performers\n300\n6.46\n2.35\n\n\nPeerSupport\nLow performers\n180\n7.91\n2.05\n\n\nPeerSupport\nMedium performers\n520\n7.93\n1.95\n\n\nPeerSupport\nHigh performers\n300\n8.08\n1.92\n\n\nRewards\nLow performers\n180\n6.38\n2.43\n\n\nRewards\nMedium performers\n520\n6.25\n2.52\n\n\nRewards\nHigh performers\n300\n7.19\n2.34\n\n\n\n\n\nIn the next section we will test if any of these differences are statistically significant or simply due to random variation.\n\n\nANOVA: Interpreting the results\nTo interpret the results of a one-way ANOVA appropriately, three aspects should be considered:\n\n\nthe distribution of the outcome variable across the comparison groups, to understand the underlying group patterns (chart below);\n\n\nthe overall ANOVA test statistic, which assesses whether any statistically significant differences exist between group means (Table 3);\n\n\nthe post-hoc pairwise comparisons, which identify where those differences stand and confirm whether the observed effects align with the expected group averages (Table 4);.\n\n\n\n\nOverall Engagement vs Performance\n\n\n\n\n\n\nTipUsing ggplot2 to create boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Overall Engagement vs Performance: Building a boxplot with ggplot\n# ------------------------------------------------------------\nchart1&lt;-df|&gt;\n  filter(!is.na(Performance)) |&gt; #ensures we remove any missing values\n  filter(!is.na(Engagement)) |&gt; #ensures we remove any missing values\n  ggplot(aes(y=Engagement, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.3, size=1.2, position = position_dodge())+\n  labs(x=\"Performance Group\", y=\"Engagement Score\", caption=(\"Number of observations: 1000\")) +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Overall Engagement by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart1\n\n\n\n\n\nOverall Engagement by Performance Group (click the chart to enlarge)\n\n\n\n\nFor the current dataset, Engagement differs significantly across performance groups (F(2,997)=22.50, p&lt;.001, Î·Â²=0.04). High performers report higher engagement than both medium and low performers, with all pairwise differences statistically significant. However, the effect size is modest, suggesting engagement explains only a small share of performance differences.\n\n\nCode\n# ------------------------------------------------------------\n# Create a summary table for ANOVA tests\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Create a helper object for the summary table: eta-squared from aov object (one-way ANOVA)\n# ------------------------------------------------------------\neta_sq_oneway &lt;- function(fit) {\n  a &lt;- summary(fit)[[1]]\n  ss_effect &lt;- a[[\"Sum Sq\"]][1]\n  ss_total  &lt;- sum(a[[\"Sum Sq\"]], na.rm = TRUE)\n  ss_effect / ss_total\n}\n\n# ------------------------------------------------------------\n# Create and format Table 3: ANOVA results (Driver-by-driver)\n# ------------------------------------------------------------\nanova_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  \n  a &lt;- summary(fit)[[1]]\n  \n  tibble(\n    Driver = d,\n    df1 = a$Df[1],\n    df2 = a$Df[2],\n    F = a$`F value`[1],\n    p_value = a$`Pr(&gt;F)`[1],\n    eta_sq = eta_sq_oneway(fit)\n  )\n})) %&gt;%\n  arrange(p_value)\n\nkable(\n  anova_table,\n  digits = 4,\n  caption = \"Table 3: One-way ANOVA results: Performance group differences by driver\")\n\n\n\nTable 3: One-way ANOVA results: Performance group differences by driver\n\n\nDriver\ndf1\ndf2\nF\np_value\neta_sq\n\n\n\n\nAccomplishment\n2\n997\n64.7951\n0.0000\n0.1150\n\n\nEngagement\n2\n997\n22.4963\n0.0000\n0.0432\n\n\nRewards\n2\n997\n14.7456\n0.0000\n0.0287\n\n\nManagerRelations\n2\n997\n9.4776\n0.0001\n0.0187\n\n\nGoals\n2\n997\n0.8058\n0.4470\n0.0016\n\n\nPeerSupport\n2\n997\n0.6747\n0.5095\n0.0014\n\n\n\n\n\nPerceived Accomplishment shows the strongest differences by performance group (F(2,997)=64.80, p&lt;.001, Î·Â²=0.12). High performers report substantially higher accomplishment than medium and low performers, and medium performers also score higher than low performers.This represents a moderate effect, indicating accomplishment is closely associated with performance outcomes.\nManager relations vary significantly by performance group (F(2,997)=9.48, p&lt;.001, Î·Â²=0.02). Low performers report better manager relations than both medium and high performers, while no meaningful difference is observed between medium and high performers.Overall, the effect is small, suggesting limited practical impact despite statistical significance.\nPerceptions of Rewards differ significantly across performance groups (F(2,997)=14.75, p&lt;.001, Î·Â²=0.03). High performers report higher rewards than both low and medium performers, while no significant difference is observed between low and medium performers. The effect size is also small.\n\n\nCode\n# ------------------------------------------------------------\n# Create and format Table 4: Tukey HSD post-hoc results (all drivers)\n# ------------------------------------------------------------\ntukey_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  tuk &lt;- TukeyHSD(fit)\n  \n  broom::tidy(tuk) %&gt;%\n    mutate(\n      Driver = d,\n      Comparison = contrast,\n      Difference = estimate,\n      CI_Lower = conf.low,\n      CI_Upper = conf.high,\n      p_adj = adj.p.value\n    ) %&gt;%\n    select(Driver, Comparison, Difference, CI_Lower, CI_Upper, p_adj) %&gt;%\n    arrange(p_adj)\n}))\n\nkable(\n  tukey_table,\n  digits = 4,\n  caption = \"Table 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\"\n)\n\n\n\nTable 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\n\n\n\n\n\n\n\n\n\n\nDriver\nComparison\nDifference\nCI_Lower\nCI_Upper\np_adj\n\n\n\n\nEngagement\nHigh performers-Low performers\n1.3647\n0.8867\n1.8426\n0.0000\n\n\nEngagement\nMedium performers-Low performers\n0.8136\n0.3752\n1.2520\n0.0000\n\n\nEngagement\nHigh performers-Medium performers\n0.5511\n0.1835\n0.9186\n0.0013\n\n\nRewards\nHigh performers-Medium performers\n0.9453\n0.5283\n1.3623\n0.0000\n\n\nRewards\nHigh performers-Low performers\n0.8182\n0.2760\n1.3605\n0.0012\n\n\nRewards\nMedium performers-Low performers\n-0.1271\n-0.6244\n0.3703\n0.8203\n\n\nAccomplishment\nHigh performers-Low performers\n2.2807\n1.8104\n2.7510\n0.0000\n\n\nAccomplishment\nMedium performers-Low performers\n1.4058\n0.9745\n1.8372\n0.0000\n\n\nAccomplishment\nHigh performers-Medium performers\n0.8748\n0.5132\n1.2365\n0.0000\n\n\nManagerRelations\nMedium performers-Low performers\n-0.8547\n-1.3417\n-0.3678\n0.0001\n\n\nManagerRelations\nHigh performers-Low performers\n-0.8680\n-1.3989\n-0.3371\n0.0004\n\n\nManagerRelations\nHigh performers-Medium performers\n-0.0133\n-0.4215\n0.3950\n0.9968\n\n\nGoals\nHigh performers-Medium performers\n-0.2346\n-0.6686\n0.1993\n0.4131\n\n\nGoals\nHigh performers-Low performers\n-0.1563\n-0.7206\n0.4080\n0.7923\n\n\nGoals\nMedium performers-Low performers\n0.0783\n-0.4393\n0.5959\n0.9329\n\n\nPeerSupport\nHigh performers-Medium performers\n0.1493\n-0.1843\n0.4830\n0.5451\n\n\nPeerSupport\nHigh performers-Low performers\n0.1747\n-0.2592\n0.6085\n0.6119\n\n\nPeerSupport\nMedium performers-Low performers\n0.0253\n-0.3726\n0.4233\n0.9878\n\n\n\n\n\n\n\nVisualising the results\n\n\n\n\n\n\nTipUsing ggplot2 to create a grid chart\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Create and format a grid chart with 6 views:  95% confidence interval plots (Engagement + Engagement drivers) + ANOVA p-values + Î·Â²\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Build a long format dataframe (via pivot_longer()) for faceting\n# ------------------------------------------------------------\ndf_long &lt;- df %&gt;%\n  select(Performance, all_of(drivers)) %&gt;%\n  pivot_longer(\n    cols = all_of(drivers),\n    names_to = \"Driver\",\n    values_to = \"Score\"\n  ) %&gt;%\n  filter(!is.na(Performance), !is.na(Score)) %&gt;%\n  mutate(Driver = factor(Driver, levels = drivers))\n\n# ------------------------------------------------------------\n# Build labels from previous ANOVA summary table (p + eta-squared)\n# ------------------------------------------------------------\nstats_labels &lt;- anova_table %&gt;%\n  select(Driver, p_value, eta_sq) %&gt;%\n  mutate(\n    p_txt = ifelse(\n      p_value &lt; 0.001,\n      \"p &lt; 0.001\",\n      paste0(\"p = \", formatC(p_value, format = \"f\", digits = 3))\n    ),\n    eta_txt = paste0(\"\\u03b7\\u00b2 = \", formatC(eta_sq, format = \"f\", digits = 3)),\n    stat_label = paste0(\"ANOVA \", p_txt, \"  |  \", eta_txt),\n    x = 1\n  )\n\n# ------------------------------------------------------------\n# Build a helper object for label positions per facet, so labels appear near the top of each panel\n# ------------------------------------------------------------\n\ny_pos &lt;- df_long %&gt;%\n  group_by(Driver) %&gt;%\n  summarise(\n    y = max(Score, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nstats_plot &lt;- left_join(stats_labels, y_pos, by = \"Driver\")\n\n# ------------------------------------------------------------\n# Create and format the actual grid plot\n# ------------------------------------------------------------\nchart_grid &lt;- ggplot(df_long, aes(x = Performance, y = Score, colour = Performance)) +\n  stat_summary(fun = \"mean\", geom = \"point\", size = 1.8) +\n  stat_summary(\n    fun.data = mean_cl_boot,\n    geom = \"errorbar\",\n    width = 0.25,\n    size = 0.9\n  ) +\n  facet_wrap(~ Driver, ncol = 3, scales = \"free_y\") +\n  geom_text(\n    data = stats_plot,\n    aes(x = x, y = y, label = stat_label),\n    inherit.aes = FALSE,\n    hjust = 0,\n    vjust = 1,\n    size = 3.3,\n    colour = \"grey20\"\n  ) +\n  labs(\n    x = \"Performance Group\",\n    y = \"Score\",\n    caption = \"Note: Points show group means; error bars show 95% bootstrap confidence intervals.\"\n  ) +\n  ggtitle(\"Overall Engagement and Engagement Drivers by Performance Group\", subtitle = \"One-way ANOVA (Score ~ Performance) per panel. Effect size reported as \\u03b7\\u00b2.\") +\n  theme_bw() +\n  theme(\n    strip.text = element_text(size = 12, face = \"bold\"),\n    axis.text.x = element_text(size = 10, face = \"italic\", angle = 15, hjust = 1),\n    axis.title = element_text(size = 13, face = \"bold\"),\n    plot.caption = element_text(size = 9, colour = \"grey30\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\") +\n  scale_colour_brewer(palette = \"Set2\")+\n  scale_x_discrete(labels = c(\n    \"Low performers\" = \"Low\",\n    \"Medium performers\" = \"Medium\",\n    \"High performers\" = \"High\"))\n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart_grid\n\n\n\n\n\nOverall Engagement and Engagement Drivers by Performance Group (click the chart to enlarge)"
  },
  {
    "objectID": "performance-culture-rewards.html#conclusion-recommendations",
    "href": "performance-culture-rewards.html#conclusion-recommendations",
    "title": "Building a Performance Culture II",
    "section": "Conclusion & Recommendations",
    "text": "Conclusion & Recommendations\n\nConclusion\nThe results provide strong evidence that the compensation review process broadly follows a pay-for-performance principle. Higher-performing employees receive larger salary increases, equity awards, and annualized total compensation growth, and also experience greater upward movement within the salary range, as reflected in compa-ratio changes. The analysis further shows that most low performers are excluded from compensation increases (with only a small number of exceptions).\nHowever, a deeper examination within the top performance tier reveals no statistically significant differences between performance ratings 4 and 5, suggesting that differentiation among top performers may be more limited than expected.\n\n\nRecommendations\n\nReview reward differentiation within the top performance tier: The absence of meaningful differences between ratings 4 and 5 was identified through analysis rather than design assumptions. Organisations may wish to assess whether this level of differentiation aligns with their intended performance philosophy or whether additional mechanisms are needed to recognise exceptional performance.\nFormalise eligibility criteria for low performers: While the general exclusion of low performers from increases is consistent with performance-based rewards, the presence of exceptions highlights the need for clear and consistently applied eligibility guidelines.\nContinue complementing compensation increase metrics with compa-ratio analysis: Reviewing both annual increases and resulting salary positioning helps ensure that compensation decisions remain aligned with performance incentives while supporting sustainable, long-term pay structures"
  },
  {
    "objectID": "performance-culture-rewards.html#analysis-results",
    "href": "performance-culture-rewards.html#analysis-results",
    "title": "Building a Performance Culture II",
    "section": "Analysis & Results",
    "text": "Analysis & Results\n\nDescriptive Statistics\nThe descriptive statistics by performance group indicate that:\n\nAverage % increase for salary , equity awards, and annualized total compensation increases rise progressively from low to medium to high performers, consistent with a pay-for-performance structure.\nCompa-ratios are comparable across performance groups prior to the review, but diverge afterward, with higher-performing employees showing greater upward movement within the salary range following the compensation review.\n\n\n\nCode\n# ------------------------------------------------------------\n# Create and format Table 2: Descriptive Statistics (N, Mean, SD) by Performance group\n# ------------------------------------------------------------\ndesc_table &lt;- df_comp |&gt;\n  select(\n    Performance,\n    SalaryIncrease,\n    EquityIncrease,\n    TotalCompIncrease,\n    CompaRatioBefore,\n    CompaRatioAfter) |&gt;\n  pivot_longer(\n    cols = -Performance,\n    names_to = \"Metric\",\n    values_to = \"Value\") |&gt;\n  group_by(Metric, Performance) |&gt;\n  summarise(\n    N = sum(!is.na(Value)),\n    Mean = mean(Value, na.rm = TRUE),\n    SD = sd(Value, na.rm = TRUE),\n    .groups = \"drop\") |&gt;\n  arrange(Metric, Performance)\n\nkable(\n  desc_table,\n  digits = 3,\n  caption = \"Table 2:Descriptive statistics (N, Mean, SD) by Performance group\")\n\n\n\nTable 2:Descriptive statistics (N, Mean, SD) by Performance group\n\n\nMetric\nPerformance\nN\nMean\nSD\n\n\n\n\nCompaRatioAfter\nLow performers\n180\n0.983\n0.116\n\n\nCompaRatioAfter\nMedium performers\n520\n1.030\n0.119\n\n\nCompaRatioAfter\nHigh performers\n300\n1.059\n0.119\n\n\nCompaRatioBefore\nLow performers\n180\n0.982\n0.117\n\n\nCompaRatioBefore\nMedium performers\n520\n0.982\n0.116\n\n\nCompaRatioBefore\nHigh performers\n300\n0.982\n0.112\n\n\nEquityIncrease\nLow performers\n180\n0.013\n0.040\n\n\nEquityIncrease\nMedium performers\n520\n0.152\n0.120\n\n\nEquityIncrease\nHigh performers\n300\n0.272\n0.155\n\n\nSalaryIncrease\nLow performers\n180\n0.001\n0.003\n\n\nSalaryIncrease\nMedium performers\n520\n0.048\n0.015\n\n\nSalaryIncrease\nHigh performers\n300\n0.077\n0.015\n\n\nTotalCompIncrease\nLow performers\n180\n0.004\n0.011\n\n\nTotalCompIncrease\nMedium performers\n520\n0.086\n0.033\n\n\nTotalCompIncrease\nHigh performers\n300\n0.145\n0.043\n\n\n\n\n\nIn the next step, formal statistical testing using one-way ANOVA is conducted to assess whether these observed mean differences are statistically significant.\n\n\nCompensation Review Outcomes vs Performance\nAs previously mentioned, it is common in a comp review cycles to have a certain percentage of employees with a 0% increase (e.g.Â due to eligibility criteria). For this reason, in order to better illustrate the relationship between the outcomes of the compensation review process and performance we will exclude the employees with 0% increases from all the ANVOA tests conducted below.\n\nSalary Increase (%) by Performance\nThe one-way ANOVA shows a statistically significant difference in average salary increases across performance groups (F(2, 800) = 791.6, p &lt; .001). Only a very small number of low performers received a non-zero increase, indicating that most performers were not eligible for salary adjustments, with only limited exceptions.\nFocusing on the two main eligible groups, high performers received significantly higher salary increases than medium performers, as confirmed by post-hoc Tukey tests.\n\n\n\n\n\n\nTipSalary Increase (%) by Performance: R code for ANVOA\n\n\n\n\n\n\n# ------------------------------------------------------------\n# 1) ANOVA: SalaryIncrease by Performance (exclude 0% salary increases)\n# ------------------------------------------------------------\n\n#Exclude employees with 0% Salary increase\ndf_salary &lt;- df_comp |&gt;\n  filter(SalaryIncrease &gt; 0)\n\n#Simple function for ANOVA test\naov_salary &lt;- aov(SalaryIncrease ~ Performance, data = df_salary)\nsummary(aov_salary)\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)    \nPerformance   2 0.18025 0.09013   791.6 &lt;2e-16 ***\nResiduals   800 0.09109 0.00011                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Descriptive table for comparing the means between the groups\nsalary_means &lt;- df_salary |&gt;\n  group_by(Performance) |&gt;\n  summarise(\n    N = n(),\n    MeanSalaryIncrease = mean(SalaryIncrease),\n    .groups = \"drop\")\n\nsalary_means\n\n# A tibble: 3 Ã— 3\n  Performance           N MeanSalaryIncrease\n  &lt;fct&gt;             &lt;int&gt;              &lt;dbl&gt;\n1 Low performers       13             0.0103\n2 Medium performers   494             0.0501\n3 High performers     296             0.0784\n\n#Post-hoc test\nTukeyHSD(aov_salary)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = SalaryIncrease ~ Performance, data = df_salary)\n\n$Performance\n                                        diff        lwr        upr p adj\nMedium performers-Low performers  0.03982794 0.03278806 0.04686781     0\nHigh performers-Low performers    0.06808082 0.06098083 0.07518081     0\nHigh performers-Medium performers 0.02825289 0.02641127 0.03009451     0\n\n\n\n\n\n\n\n\n\n\n\nTipSalary Increase (%) vs Performance: R code for boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Salary Increase and Performance\n# ------------------------------------------------------------\nchart1&lt;-df_salary|&gt;\n  ggplot(aes(y=SalaryIncrease, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.2, size=0.8, position = position_dodge())+\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x=\"Performance Group\", y=\"Salary Increase (%)\") +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Salary Increase (%) by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart1\n\n\n\n\n\nSalary Increase (%) by Performance Group (click the chart to enlarge)\n\n\n\n\n\n\nEquity Increase (%) by Performance\nSimilar to salary increases, the one-way ANOVA indicates statistically significant differences in equity award increases across performance groups (p &lt; .001). Focusing on the main eligible groups, high performers received significantly larger equity awards than medium performers.\n\n\n\n\n\n\nTipEquity Increase (%) by Performance: R code for ANVOA\n\n\n\n\n\n\n# ------------------------------------------------------------\n# 2) ANOVA: EquityIncrease by Performance (exclude 0% equity increases)\n# ------------------------------------------------------------\n\n#Exclude employees with 0% Equity increase\ndf_equity &lt;- df_comp |&gt;\n  filter(EquityIncrease &gt; 0)\n\n#Simple function for ANOVA test\naov_equity &lt;- aov(EquityIncrease ~ Performance, data = df_equity)\nsummary(aov_equity)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nPerformance   2  1.877  0.9385   79.63 &lt;2e-16 ***\nResiduals   671  7.909  0.0118                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Descriptive table for comparing the means between the groups\nequity_means &lt;- df_equity |&gt;\n  group_by(Performance) |&gt;\n  summarise(\n    N = n(),\n    MeanEquityIncrease = mean(EquityIncrease),\n    .groups = \"drop\")\n\nequity_means\n\n# A tibble: 3 Ã— 3\n  Performance           N MeanEquityIncrease\n  &lt;fct&gt;             &lt;int&gt;              &lt;dbl&gt;\n1 Low performers       21              0.113\n2 Medium performers   384              0.205\n3 High performers     269              0.303\n\n#Post-hoc test\nTukeyHSD(aov_equity)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = EquityIncrease ~ Performance, data = df_equity)\n\n$Performance\n                                        diff        lwr       upr     p adj\nMedium performers-Low performers  0.09270833 0.03555941 0.1498573 0.0004443\nHigh performers-Low performers    0.19063073 0.13285187 0.2484096 0.0000000\nHigh performers-Medium performers 0.09792240 0.07764694 0.1181979 0.0000000\n\n\n\n\n\n\n\n\n\n\n\nTipEquity Increase (%) vs Performance: R code for boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Equity Increase and Performance\n# ------------------------------------------------------------\nchart2&lt;-df_equity|&gt;\n  ggplot(aes(y=EquityIncrease, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.2, size=0.8, position = position_dodge())+\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x=\"Performance Group\", y=\"Equity Increase (%)\") +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Equity Increase (%) by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart2\n\n\n\n\n\nEquity Increase (%) by Performance Group (click the chart to enlarge)\n\n\n\n\n\n\nAnnualised Total Compensation Increase (%) by Performance\nThe one-way ANOVA shows a statistically significant difference in annualized total compensation increases across performance groups (p &lt; .001). As with salary and equity, only a limited number of low performers received any increase.\nOn average, medium performers received an annualized total compensation increase of approximately 8â€“9%, while high performers received increases closer to 14â€“15%, highlighting a clear and meaningful differentiation in overall rewards aligned with performance.\n\n\n\n\n\n\nTipAnnualised Total Comp Increase (%) by Performance: R code for ANVOA\n\n\n\n\n\n\n# ------------------------------------------------------------\n# 3) ANOVA: TotalCompIncrease by Performance (exclude 0% total comp increases)\n# ------------------------------------------------------------\n\n#Exclude employees with 0% Total compensation increase\ndf_total &lt;- df_comp |&gt;\n  filter(TotalCompIncrease &gt; 0)\n\n#Simple function for ANOVA test\naov_total &lt;- aov(TotalCompIncrease ~ Performance, data = df_total)\nsummary(aov_total)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nPerformance   2 0.8807  0.4404   349.2 &lt;2e-16 ***\nResiduals   843 1.0631  0.0013                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Descriptive table for comparing the means between the groups\ntotal_means &lt;- df_total |&gt;\n  group_by(Performance) |&gt;\n  summarise(\n    N = n(),\n    MeanTotalCompIncrease = mean(TotalCompIncrease),\n    .groups = \"drop\")\n\ntotal_means\n\n# A tibble: 3 Ã— 3\n  Performance           N MeanTotalCompIncrease\n  &lt;fct&gt;             &lt;int&gt;                 &lt;dbl&gt;\n1 Low performers       32                0.0227\n2 Medium performers   514                0.0865\n3 High performers     300                0.145 \n\n#Post-hoc test\nTukeyHSD(aov_total)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = TotalCompIncrease ~ Performance, data = df_total)\n\n$Performance\n                                        diff        lwr        upr p adj\nMedium performers-Low performers  0.06388071 0.04868977 0.07907165     0\nHigh performers-Low performers    0.12269708 0.10719185 0.13820232     0\nHigh performers-Medium performers 0.05881637 0.05275857 0.06487417     0\n\n\n\n\n\n\n\n\n\n\n\nTipAnnualised Total Comp Increase (%) vs Performance: R code for boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Total Comp Increase and Performance\n# ------------------------------------------------------------\nchart3&lt;-df_total|&gt;\n  ggplot(aes(y=TotalCompIncrease, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.2, size=0.8, position = position_dodge())+\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x=\"Performance Group\", y=\"Total Comp (%)\") +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Annualised Total Compensation Increase (%) by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart3\n\n\n\n\n\nAnnualised Total Compensation Increase (%) by Performance Group (click the chart to enlarge)\n\n\n\n\n\n\nHigh Performers deep-dive: Total Comp Increase (%) by Performance\nTo further assess whether the compensation review outcomes support the development of a performance culture, this section examines whether meaningful differentiation exists within the top performance tier, comparing Very good performers (with a 4 rating) and Excellent performers (with a 5 rating).\n\n\n\n\n\n\nTipHigh Performers deep-dive: R code for ANVOA\n\n\n\n\n\n\n# ------------------------------------------------------------\n# 4) ANOVA: High Performers deep-dive: \n# ------------------------------------------------------------\n\n# Select high performers (ratings 4 and 5) and recode rating as a factor\ndf_total_45 &lt;- df_comp |&gt;\n  filter(PerformanceRatings %in% c(4, 5)) |&gt;\n  filter(TotalCompIncrease &gt; 0) |&gt;\n  mutate(\n    Rating45 = factor(PerformanceRatings, levels = c(4, 5)))\n\n# Simple function for ANOVA test\naov_total_45 &lt;- aov(TotalCompIncrease ~ Rating45, data = df_total_45)\nsummary(aov_total_45)\n\n             Df Sum Sq  Mean Sq F value Pr(&gt;F)\nRating45      1 0.0022 0.002218   1.228  0.269\nResiduals   298 0.5381 0.001806               \n\n# Descriptive table for comparing the means between the groups\ntotal_means_45 &lt;- df_total_45 |&gt;\n  group_by(Rating45) |&gt;\n  summarise(\n    N = n(),\n    MeanTotalCompIncrease = mean(TotalCompIncrease),\n    .groups = \"drop\")\n\ntotal_means_45\n\n# A tibble: 2 Ã— 3\n  Rating45     N MeanTotalCompIncrease\n  &lt;fct&gt;    &lt;int&gt;                 &lt;dbl&gt;\n1 4          180                 0.143\n2 5          120                 0.149\n\n\n\n\n\n\n\n\n\n\n\nTipHigh Performers deep-dive: R code for boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualize the relationship between Total Comp Increase and Performance for high performers\n# ------------------------------------------------------------\n\n#Create a new variable that caputres labesl for 4 & 5 levels of perormance\ndf_total_45 &lt;- df_total_45 |&gt;\n  mutate(RatingLabel = case_when(Rating45==4 ~ \"Very good performer\",\n                                 Rating45==5 ~ \"Excellent performer\"))\n\n#Convert the new variable to factor\ndf_total_45 &lt;- df_total_45 |&gt;\n  mutate(RatingLabel = factor(RatingLabel,\n      levels = c(\"Very good performer\", \"Excellent performer\")))\n\n\nchart4&lt;-df_total_45|&gt;\n  ggplot(aes(y=TotalCompIncrease, x=RatingLabel, colour=RatingLabel))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.2, size=0.8, position = position_dodge())+\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x=\"Performance Group\", y=\"Total Comp (%)\") +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"High Performers deep-dive: Annualised Total Comp Increase (%) by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart4\n\n\n\n\n\nHigh Performers deep-dive:Annualised Total Comp Increase (%) by Performance Group (click the chart to enlarge)\n\n\n\n\nAmong high performers, the one-way ANOVA shows no statistically significant difference in average annualized total compensation increases between Very good performers and Excellent performers (F(1, 298) = 1.23, p = .27). The average increase is very similar across the two groups (14.3% vs 14.9%), with substantial overlap in their distributions. This result indicates limited differentiation in total compensation outcomes among top performers.\n\n\nChanges in Compa-Ratio\nTo assess the impact of the compensation review process on employeesâ€™ salary positioning, another analysis looks at Compa-Ratio before and after the comp review. Because compa-ratio is measured for the same employees at two points in time, the analysis uses paired t-tests (within-employee comparisons) to test whether compa-ratio changed after the review overall and within each performance group. In addition, a delta compa-ratio (After âˆ’ Before) is calculated to summarize the magnitude and direction of movement within the salary range.\n\n\n\n\n\n\nTipChanges in Compa-Ratio: R code for paired t-tests\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Compa-ratio analysis: Before vs After compensation review\n# Method: paired t-tests (within-employee) + delta compa-ratio descriptives\n# ------------------------------------------------------------\n\nlibrary(dplyr)\n\n# 1) Create compa-ratio change (delta)\ndf_comp_adj &lt;- df_comp |&gt;\n  mutate(CompaRatioDelta = CompaRatioAfter - CompaRatioBefore)|&gt;\n  filter(SalaryIncrease &gt; 0)\n\n# 2) Overall paired test (all employees)\nt.test(\n  df_comp_adj $CompaRatioAfter,\n  df_comp_adj $CompaRatioBefore,\n  paired = TRUE)\n\n\n    Paired t-test\n\ndata:  df_comp_adj$CompaRatioAfter and df_comp_adj$CompaRatioBefore\nt = 87.828, df = 802, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.05829986 0.06096540\nsample estimates:\nmean difference \n     0.05963263 \n\n# 3) Paired t-tests by Performance group\n\nd_low    &lt;- df_comp_adj  |&gt; filter(Performance == \"Low performers\")\nd_medium &lt;- df_comp_adj  |&gt; filter(Performance == \"Medium performers\")\nd_high   &lt;- df_comp_adj  |&gt; filter(Performance == \"High performers\")\n\nt.test(d_low$CompaRatioAfter,    d_low$CompaRatioBefore,    paired = TRUE)\n\n\n    Paired t-test\n\ndata:  d_low$CompaRatioAfter and d_low$CompaRatioBefore\nt = 3.1564, df = 12, p-value = 0.008276\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.00471723 0.02574431\nsample estimates:\nmean difference \n     0.01523077 \n\nt.test(d_medium$CompaRatioAfter, d_medium$CompaRatioBefore, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  d_medium$CompaRatioAfter and d_medium$CompaRatioBefore\nt = 92.46, df = 493, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.04904052 0.05117000\nsample estimates:\nmean difference \n     0.05010526 \n\nt.test(d_high$CompaRatioAfter,   d_high$CompaRatioBefore,   paired = TRUE)\n\n\n    Paired t-test\n\ndata:  d_high$CompaRatioAfter and d_high$CompaRatioBefore\nt = 95.946, df = 295, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.07589377 0.07907244\nsample estimates:\nmean difference \n     0.07748311 \n\n# 4) Descriptive statistics for compa-ratio movement\ncompa_summary &lt;- df_comp_adj  |&gt;\n  group_by(Performance) |&gt;\n  summarise(\n    N = n(),\n    MeanCompaRatioBefore = mean(CompaRatioBefore, na.rm = TRUE),\n    MeanCompaRatioAfter  = mean(CompaRatioAfter, na.rm = TRUE),\n    MeanDelta            = mean(CompaRatioDelta, na.rm = TRUE),\n    SDDelta              = sd(CompaRatioDelta, na.rm = TRUE),\n    .groups = \"drop\")\n\ncompa_summary\n\n# A tibble: 3 Ã— 6\n  Performance       N MeanCompaRatioBefore MeanCompaRatioAfter MeanDelta SDDelta\n  &lt;fct&gt;         &lt;int&gt;                &lt;dbl&gt;               &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Low performeâ€¦    13                0.982               0.997    0.0152  0.0174\n2 Medium perfoâ€¦   494                0.982               1.03     0.0501  0.0120\n3 High performâ€¦   296                0.981               1.06     0.0775  0.0139\n\n\n\n\n\n\n\n\n\n\n\nTipChanges in Compa-Ratio: R code for boxplot\n\n\n\n\n\n\nchart5&lt;-df_comp_adj |&gt;\n  ggplot(aes(y=CompaRatioDelta, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.2, size=0.8, position = position_dodge())+\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x=\"Performance Group\", y=\"Changes in Compa-Ratio\") +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Changes in Compa-Ratio by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart5\n\n\n\n\n\nCompa-ratio change by Performance Group (click the chart to enlarge)\n\n\n\n\nThe results show a statistically significant increase in compa-ratio following the compensation review across all performance groups. On average, medium performers experienced an increase of approximately 5.0 percentage points, while high performers saw a larger average increase of around 7.8 percentage points, indicating stronger upward movement within the salary range for higher performers. Although only a small number of low performers received salary adjustments, those who did also showed a modest but statistically significant increase in compa-ratio. Overall, these findings suggest that the compensation review process not only differentiated reward levels, but also systematically improved salary positioning in line with performance, reinforcing a pay-for-performance structure."
  },
  {
    "objectID": "performance-culture-engagement.html#analysis-results",
    "href": "performance-culture-engagement.html#analysis-results",
    "title": "Building a Performance Culture I",
    "section": "Analysis & Results",
    "text": "Analysis & Results\n\nDescriptive Statistics\nWhile in this case the purpose and methods of the analysis were pre-defined, it can never be a bad idea to explore your data in order to understand it and notice any unexpected pattern.\nThe average engagement scores by performance groups shows that:\n\nFor Overall Engagement and Accomplishment, engagement increases with Performance;\nFor Goals and Peer Support, the averages are quite similar across Low, Medium and High performers;\nLow performers are on average more satisfied with their Manager Relation, compared to the other performance groups;\nHigh performers are on average more satisfied with their Rewards, compared to the employees in the other performance groups.\n\n\n\nCode\n# ------------------------------------------------------------\n# Build 2 helper variables: 1st to  use Performance as the grouping variable and 2nd to select all the drivers of engagement\n# ------------------------------------------------------------\ngroup_var &lt;- \"Performance\"\n\ndrivers &lt;- c(\n  \"Engagement\",\n  \"Rewards\",\n  \"Accomplishment\",\n  \"ManagerRelations\",\n  \"Goals\",\n  \"PeerSupport\")\n\n# ------------------------------------------------------------\n# Create and format Table 2: Descriptive Statistics (N, Mean, SD) by Performance group\n# ------------------------------------------------------------\ndesc_table &lt;- df |&gt;\n  select(Performance, all_of(drivers)) |&gt;\n  pivot_longer(all_of(drivers), names_to = \"Driver\", values_to = \"Score\") |&gt;\n  group_by(Driver, Performance) |&gt;\n  summarise(\n    N = sum(!is.na(Score)),\n    Mean = mean(Score, na.rm = TRUE),\n    SD = sd(Score, na.rm = TRUE),\n    .groups = \"drop\") |&gt;\n  arrange(Driver, Performance)\n\nkable(\n  desc_table,\n  digits = 2,\n  caption = \"Table 2: Descriptive statistics (N, Mean, SD) by Performance group\")\n\n\n\nTable 2: Descriptive statistics (N, Mean, SD) by Performance group\n\n\nDriver\nPerformance\nN\nMean\nSD\n\n\n\n\nAccomplishment\nLow performers\n180\n5.62\n2.23\n\n\nAccomplishment\nMedium performers\n520\n7.03\n2.19\n\n\nAccomplishment\nHigh performers\n300\n7.90\n1.94\n\n\nEngagement\nLow performers\n180\n6.41\n2.39\n\n\nEngagement\nMedium performers\n520\n7.23\n2.17\n\n\nEngagement\nHigh performers\n300\n7.78\n1.98\n\n\nGoals\nLow performers\n180\n6.32\n2.57\n\n\nGoals\nMedium performers\n520\n6.40\n2.55\n\n\nGoals\nHigh performers\n300\n6.16\n2.54\n\n\nManagerRelations\nLow performers\n180\n7.33\n2.30\n\n\nManagerRelations\nMedium performers\n520\n6.47\n2.46\n\n\nManagerRelations\nHigh performers\n300\n6.46\n2.35\n\n\nPeerSupport\nLow performers\n180\n7.91\n2.05\n\n\nPeerSupport\nMedium performers\n520\n7.93\n1.95\n\n\nPeerSupport\nHigh performers\n300\n8.08\n1.92\n\n\nRewards\nLow performers\n180\n6.38\n2.43\n\n\nRewards\nMedium performers\n520\n6.25\n2.52\n\n\nRewards\nHigh performers\n300\n7.19\n2.34\n\n\n\n\n\nIn the next section we will test if any of these differences are statistically significant or simply due to random variation.\n\n\nANOVA: Interpreting the results\nTo interpret the results of a one-way ANOVA appropriately, three aspects should be considered:\n\n\nthe distribution of the outcome variable across the comparison groups, to understand the underlying group patterns (chart below);\n\n\nthe overall ANOVA test statistic, which assesses whether any statistically significant differences exist between group means (Table 3);\n\n\nthe post-hoc pairwise comparisons, which identify where those differences stand and confirm whether the observed effects align with the expected group averages (Table 4);.\n\n\n\n\nOverall Engagement vs Performance\n\n\n\n\n\n\nTipUsing ggplot2 to create boxplot\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Visualise the relationship between Overall Engagement vs Performance: Building a boxplot with ggplot\n# ------------------------------------------------------------\nchart1&lt;-df|&gt;\n  filter(!is.na(Performance)) |&gt; #ensures we remove any missing values\n  filter(!is.na(Engagement)) |&gt; #ensures we remove any missing values\n  ggplot(aes(y=Engagement, x=Performance, colour=Performance))+\n  geom_boxplot(width = 0.45, outlier.alpha = 0.15, colour = \"grey40\") +\n  geom_jitter(width = 0.12, alpha = 0.08, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun=\"mean\", geom=\"point\", size=2)+\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width=0.3, size=1.2, position = position_dodge())+\n  labs(x=\"Performance Group\", y=\"Engagement Score\", caption=(\"Number of observations: 1000\")) +\n  theme_bw() + \n  theme(plot.title = element_text(size=14, face=\"bold.italic\"),\n        axis.title= element_text(size=14, face=\"bold\"),\n        axis.text.x = element_text(size = 12, face=\"italic\"),\n        axis.text.y=element_text(size=13, face=\"bold\"),\n        legend.position = \"none\",\n        plot.caption = element_text(size=11, face=\"italic\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  scale_colour_brewer(palette = \"Set2\")+\n  ggtitle(\"Overall Engagement by Performance Group\", \n          subtitle = \"(95% bootstrap confidence intervals for the mean)\") \n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart1\n\n\n\n\n\nOverall Engagement by Performance Group (click the chart to enlarge)\n\n\n\n\nFor the current dataset, Engagement differs significantly across performance groups (F(2,997)=22.50, p&lt;.001, Î·Â²=0.04). High performers report higher engagement than both medium and low performers, with all pairwise differences statistically significant. However, the effect size is modest, suggesting engagement explains only a small share of performance differences.\n\n\nCode\n# ------------------------------------------------------------\n# Create a summary table for ANOVA tests\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Create a helper object for the summary table: eta-squared from aov object (one-way ANOVA)\n# ------------------------------------------------------------\neta_sq_oneway &lt;- function(fit) {\n  a &lt;- summary(fit)[[1]]\n  ss_effect &lt;- a[[\"Sum Sq\"]][1]\n  ss_total  &lt;- sum(a[[\"Sum Sq\"]], na.rm = TRUE)\n  ss_effect / ss_total\n}\n\n# ------------------------------------------------------------\n# Create and format Table 3: ANOVA results (Driver-by-driver)\n# ------------------------------------------------------------\nanova_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  \n  a &lt;- summary(fit)[[1]]\n  \n  tibble(\n    Driver = d,\n    df1 = a$Df[1],\n    df2 = a$Df[2],\n    F = a$`F value`[1],\n    p_value = a$`Pr(&gt;F)`[1],\n    eta_sq = eta_sq_oneway(fit)\n  )\n})) %&gt;%\n  arrange(p_value)\n\nkable(\n  anova_table,\n  digits = 4,\n  caption = \"Table 3: One-way ANOVA results: Performance group differences by driver\")\n\n\n\nTable 3: One-way ANOVA results: Performance group differences by driver\n\n\nDriver\ndf1\ndf2\nF\np_value\neta_sq\n\n\n\n\nAccomplishment\n2\n997\n64.7951\n0.0000\n0.1150\n\n\nEngagement\n2\n997\n22.4963\n0.0000\n0.0432\n\n\nRewards\n2\n997\n14.7456\n0.0000\n0.0287\n\n\nManagerRelations\n2\n997\n9.4776\n0.0001\n0.0187\n\n\nGoals\n2\n997\n0.8058\n0.4470\n0.0016\n\n\nPeerSupport\n2\n997\n0.6747\n0.5095\n0.0014\n\n\n\n\n\nPerceived Accomplishment shows the strongest differences by performance group (F(2,997)=64.80, p&lt;.001, Î·Â²=0.12). High performers report substantially higher accomplishment than medium and low performers, and medium performers also score higher than low performers.This represents a moderate effect, indicating accomplishment is closely associated with performance outcomes.\nManager relations vary significantly by performance group (F(2,997)=9.48, p&lt;.001, Î·Â²=0.02). Low performers report better manager relations than both medium and high performers, while no meaningful difference is observed between medium and high performers.Overall, the effect is small, suggesting limited practical impact despite statistical significance.\nPerceptions of Rewards differ significantly across performance groups (F(2,997)=14.75, p&lt;.001, Î·Â²=0.03). High performers report higher rewards than both low and medium performers, while no significant difference is observed between low and medium performers. The effect size is also small.\n\n\nCode\n# ------------------------------------------------------------\n# Create and format Table 4: Tukey HSD post-hoc results (all drivers)\n# ------------------------------------------------------------\ntukey_table &lt;- bind_rows(lapply(drivers, function(d) {\n  f &lt;- as.formula(paste(d, \"~\", group_var))\n  fit &lt;- aov(f, data = df)\n  tuk &lt;- TukeyHSD(fit)\n  \n  broom::tidy(tuk) %&gt;%\n    mutate(\n      Driver = d,\n      Comparison = contrast,\n      Difference = estimate,\n      CI_Lower = conf.low,\n      CI_Upper = conf.high,\n      p_adj = adj.p.value\n    ) %&gt;%\n    select(Driver, Comparison, Difference, CI_Lower, CI_Upper, p_adj) %&gt;%\n    arrange(p_adj)\n}))\n\nkable(\n  tukey_table,\n  digits = 4,\n  caption = \"Table 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\"\n)\n\n\n\nTable 4: Tukey HSD post-hoc pairwise comparisons (adjusted p-values)\n\n\n\n\n\n\n\n\n\n\nDriver\nComparison\nDifference\nCI_Lower\nCI_Upper\np_adj\n\n\n\n\nEngagement\nHigh performers-Low performers\n1.3647\n0.8867\n1.8426\n0.0000\n\n\nEngagement\nMedium performers-Low performers\n0.8136\n0.3752\n1.2520\n0.0000\n\n\nEngagement\nHigh performers-Medium performers\n0.5511\n0.1835\n0.9186\n0.0013\n\n\nRewards\nHigh performers-Medium performers\n0.9453\n0.5283\n1.3623\n0.0000\n\n\nRewards\nHigh performers-Low performers\n0.8182\n0.2760\n1.3605\n0.0012\n\n\nRewards\nMedium performers-Low performers\n-0.1271\n-0.6244\n0.3703\n0.8203\n\n\nAccomplishment\nHigh performers-Low performers\n2.2807\n1.8104\n2.7510\n0.0000\n\n\nAccomplishment\nMedium performers-Low performers\n1.4058\n0.9745\n1.8372\n0.0000\n\n\nAccomplishment\nHigh performers-Medium performers\n0.8748\n0.5132\n1.2365\n0.0000\n\n\nManagerRelations\nMedium performers-Low performers\n-0.8547\n-1.3417\n-0.3678\n0.0001\n\n\nManagerRelations\nHigh performers-Low performers\n-0.8680\n-1.3989\n-0.3371\n0.0004\n\n\nManagerRelations\nHigh performers-Medium performers\n-0.0133\n-0.4215\n0.3950\n0.9968\n\n\nGoals\nHigh performers-Medium performers\n-0.2346\n-0.6686\n0.1993\n0.4131\n\n\nGoals\nHigh performers-Low performers\n-0.1563\n-0.7206\n0.4080\n0.7923\n\n\nGoals\nMedium performers-Low performers\n0.0783\n-0.4393\n0.5959\n0.9329\n\n\nPeerSupport\nHigh performers-Medium performers\n0.1493\n-0.1843\n0.4830\n0.5451\n\n\nPeerSupport\nHigh performers-Low performers\n0.1747\n-0.2592\n0.6085\n0.6119\n\n\nPeerSupport\nMedium performers-Low performers\n0.0253\n-0.3726\n0.4233\n0.9878\n\n\n\n\n\n\n\nVisualising the results\n\n\n\n\n\n\nTipUsing ggplot2 to create a grid chart\n\n\n\n\n\n\n# ------------------------------------------------------------\n# Create and format a grid chart with 6 views:  95% confidence interval plots (Engagement + Engagement drivers) + ANOVA p-values + Î·Â²\n# ------------------------------------------------------------\n\n# ------------------------------------------------------------\n# Build a long format dataframe (via pivot_longer()) for faceting\n# ------------------------------------------------------------\ndf_long &lt;- df %&gt;%\n  select(Performance, all_of(drivers)) %&gt;%\n  pivot_longer(\n    cols = all_of(drivers),\n    names_to = \"Driver\",\n    values_to = \"Score\"\n  ) %&gt;%\n  filter(!is.na(Performance), !is.na(Score)) %&gt;%\n  mutate(Driver = factor(Driver, levels = drivers))\n\n# ------------------------------------------------------------\n# Build labels from previous ANOVA summary table (p + eta-squared)\n# ------------------------------------------------------------\nstats_labels &lt;- anova_table %&gt;%\n  select(Driver, p_value, eta_sq) %&gt;%\n  mutate(\n    p_txt = ifelse(\n      p_value &lt; 0.001,\n      \"p &lt; 0.001\",\n      paste0(\"p = \", formatC(p_value, format = \"f\", digits = 3))\n    ),\n    eta_txt = paste0(\"\\u03b7\\u00b2 = \", formatC(eta_sq, format = \"f\", digits = 3)),\n    stat_label = paste0(\"ANOVA \", p_txt, \"  |  \", eta_txt),\n    x = 1\n  )\n\n# ------------------------------------------------------------\n# Build a helper object for label positions per facet, so labels appear near the top of each panel\n# ------------------------------------------------------------\n\ny_pos &lt;- df_long %&gt;%\n  group_by(Driver) %&gt;%\n  summarise(\n    y = max(Score, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nstats_plot &lt;- left_join(stats_labels, y_pos, by = \"Driver\")\n\n# ------------------------------------------------------------\n# Create and format the actual grid plot\n# ------------------------------------------------------------\nchart_grid &lt;- ggplot(df_long, aes(x = Performance, y = Score, colour = Performance)) +\n  stat_summary(fun = \"mean\", geom = \"point\", size = 1.8) +\n  stat_summary(\n    fun.data = mean_cl_boot,\n    geom = \"errorbar\",\n    width = 0.25,\n    size = 0.9\n  ) +\n  facet_wrap(~ Driver, ncol = 3, scales = \"free_y\") +\n  geom_text(\n    data = stats_plot,\n    aes(x = x, y = y, label = stat_label),\n    inherit.aes = FALSE,\n    hjust = 0,\n    vjust = 1,\n    size = 3.3,\n    colour = \"grey20\"\n  ) +\n  labs(\n    x = \"Performance Group\",\n    y = \"Score\",\n    caption = \"Note: Points show group means; error bars show 95% bootstrap confidence intervals.\"\n  ) +\n  ggtitle(\"Overall Engagement and Engagement Drivers by Performance Group\", subtitle = \"One-way ANOVA (Score ~ Performance) per panel. Effect size reported as \\u03b7\\u00b2.\") +\n  theme_bw() +\n  theme(\n    strip.text = element_text(size = 12, face = \"bold\"),\n    axis.text.x = element_text(size = 10, face = \"italic\", angle = 15, hjust = 1),\n    axis.title = element_text(size = 13, face = \"bold\"),\n    plot.caption = element_text(size = 9, colour = \"grey30\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\") +\n  scale_colour_brewer(palette = \"Set2\")+\n  scale_x_discrete(labels = c(\n    \"Low performers\" = \"Low\",\n    \"Medium performers\" = \"Medium\",\n    \"High performers\" = \"High\"))\n\n\n\n\n\n\nCode\n# ------------------------------------------------------------\n# Print the chart\n# ------------------------------------------------------------\nchart_grid\n\n\n\n\n\nOverall Engagement and Engagement Drivers by Performance Group (click the chart to enlarge)"
  }
]